\section{The Compiler}
\label{sec:compiler}


In this section we present our compiler. We start by sketching its architecture.

The compiler accepts an SQL query and schema definition (essentially create table statements for the relations the query accesses) as input. The parser turns the input query into a first intermediate representation (IR) that is somewhat reminiscent of relational algebra. The first compilation stage generates trigger programs for performing multilevel incremental view maintenance (IVM). The statements of these trigger programs increment the values of view data structures (called maps) by expressions of this IR. The IR and basics of the transformation are described in Section~\ref{sec:compiler_calc}. Section~\ref{sec:simplification} presents optimizations for simplifying IRs in the first compilation stage.

In Section~\ref{sec:advanced-rewriting} we discuss the creation of triggers for multi-level incremental view maintenance by extracting and materializing strict subexpressions rather than the full query. This is necessary to be able to deal with nested aggregation which otherwise, if we always materialize the largest query we can, leads to recursion in compilation that does not terminate. In general, the choice of subquery to materialize and incrementally maintain is a degree of freedom in query optimization. In this section we give heuristic rules for making this choice.

The next stage of the compiler, described in Section~\ref{sec:kthree}, turns the statements of the trigger program created in the first stage into an IR for purely functional programming, essentially lambda calculus without general recursion but with special higher-order functions for transforming collections. This stage allows us to perform deforestation and fusion optimizations too low-level to have expression in the first, relational algebra-like IR.

Section~\ref{sec:codegen} describes our infrastructure for code generation, which makes use of a third imperative IR, for generating and imperative programs and performing final, low-level optimization before actual code is emitted. 

Section~\ref{sec:runtime} describes our runtime system including the machinery for reading update streams.

TODO: show an architecture diagram.




\subsection{Queries with binding patterns, deltas, and recursive IVM}
\label{sec:compiler_calc}


Next we develop an IR for SQL queries that is suitable for compilation of database queries and to perform the transformations necessary to enable efficient multilevel IVM. This language is a refinement of the query language defined in \cite{koch-pods:10}, but here we aim at better readability and avoid unnecessary formality. We will use SQL syntax wherever we can. The IR is introduced as we discuss its desiderata.

\begin{itemize}
\item
It is desirable for the IR to be small-step compositional, which means that any natural syntactical subexpression must be a valid query and member of the IR. This is true for relational algebra and in essence true for SQL, if one assigns a natural meaning to subexpressions such as ``A<B'' (return 1 if the values of parameters $A$ and $B$ given from outside the query satisfy A<B, and 0 otherwise) and ``from R'' (select * from R). 

This has two particular implications: First, elements of our IR are queries with binding patterns. Binding patterns represent information flow. In general, this flow is not exclusively bottom-up.
Some of an expression's variables are input variables or parameters which cannot be computed from the query but have to be given to the query so that it can be evaluated. The most interesting case of this is a correlated nested aggregate, viewed in isolation (which must be possible for small-step compositionality). In such an aggregate, the correlation variable from the outside is such an input variable. The aggregate query can only be computed if a value for the input variable is given.

The second implication is that conditions have to be first-class citizens of the IR and valid queries.

The solution is to think of queries as relational algebra expressions with binding patterns. Each expression $Q$ has input variables or parameters $\vec{x_{in}}$ and a set of output variables $\vec{x_{out}}$, which form the schema of the query result. We denote such an expression as $Q[\vec{x_{in}}][\vec{x_{out}}]$. The input variables are those that are not {\em range-restricted} in a calculus formulation, or equivalently have to be understood as {\em parameters} in a SQL query because their values cannot be computed from the database: They have to be provided so that the query can be evaluated.

Examples. Assume relation schema $R(A,B)$. All of the following expressions are valid queries of our IR (using SQL notation), typed by indicating the input and output variables..
\begin{itemize}
\item
   (select * from R)[][A,B]
\item
   R[][A,B]
\item
   (C<D)[C,D][]
\item
   (select A from R where B < C)[C][A]
\item
   (select * from R r1 where r1.B < (select sum(r2.B) Bsum from R r2 where r1.A > r2.A)[][r1.A, r1.B].
The nested aggregate subexpression in this query has binding pattern [r1.A][Bsum] itself.
\end{itemize}



\item
The language must be closed under taking deltas, i.e. for any query, its delta query must be a member of the language too. This in particular requires us to be able to express deletions as elements of the IR.

We address this by assuming tuples have {\em integer} multiplicities. This generalizes the
muliset semantics of SQL (where tuple multiplicities are natural numbers) to also allow negative multiplicities. Thus insertions and databases are modeled in the same way, using only non-negative tuple multiplicity (and the current database can be equivalently be thought of as an insertion into the empty database). Deletions are modeled using negative tuple multiplicities.

The query operators naturally generalize bag semantics: Unions sum up multiplicities (e.g, 2-3 = -1, which differs from SQL multisite semantics, where 2-3=0. This is necessary for the associativity of key query optimization and incrementation). Projections are sum-aggregates, and joins perform integer multiplication on the multiplicities of paired tuples.

\item
Aggregate queries dominate analytical workloads and can greatly profit from incremental view maintenance, also because refreshing such query results often just means to update some aggregate values rather than change the table structure (i.e., add or remove tuples). Efficiency can profit from a language that is optimized for aggregate query processing.

We deviate from usual SQL semantics and let an aggregate query expression represent the aggregate
value in the multiplicity of the output tuples specified by the output variables. Thus we would
represent a SQL query
{\tt select A, sum(B) as SumB from R group by A}
as
{\tt (select sum(B) from R)[][A]} and the latter does not define a binary relation with
columns A and SumB but a unary relation in which each tuple's multiplicity is the sum of the multiplicities of the tuples grouped together and aggregated into one.
\end{itemize}


The fragment of SQL we cover in this paper, and thus the IR, supports the operations of 
relational union, natural join, sum-aggregation, and atomic expressions, which are either relation accesses or atomic conditions of the form $x \;\theta; y$, where $\theta$ is $=$, $\le$, or $<$ and
$x$ and $y$ are {\em terms}. Terms are built from column names, queries (!), and arithmetic expressions over terms. Queries used as terms must not have output variables (thus they compute a singleton tuple rather than a multi-tuple relation; the typical case is an aggregate without group-by) and evaluate to the multiplicity of result tuple. We view selections as natural joins of a query with a condition as in 
relational calculus or catalog syntax. Projections are redundant with sum-aggregates that group by the columns not to be projected away. Count and avg aggregates can be expressed in terms of sum-aggregates.

Note that this language specification covers most of the core features of SQL. It excludes universal quantification (``where not exists''), null values and outer joins (which have the hugely undesirably property of being nonassociative, which is a problem for incremental computation), and 
min/max aggregates. The latter can be supported in incremental evaluation but require additional data structures to support deletion. (We have to keep around all the tuples being aggregated to deal with the case that the min or max tuple gets deleted.) We do not further cover min and max aggregates in this paper.


\subsubsection{Computing the delta of a query.}

This language has the nice property of being closed under taking deltas. For each query expression $Q$, there
is an expression $\Delta Q$ that expresses how the result of $Q$ changes as the database $D$ is changed by update workload $\Delta D$. This works for updates containing an unbounded number of insertions and deletions, but we will subsequently only study single-tuple inserts and deletes.
The reason for this is that such updates allow for particularly efficient view refresh code that
can be run to respond online to each tuple change.

Proposition: The query language is closed under taking deltas.

Thanks to the strong compositionality of the language, we only have to give delta rules for the 
individual operators. These rules a given and studied in detail in \cite{koch-pods:10}. In short,
\begin{eqnarray*}
\Delta(Q_1 \cup Q_2)    &:=& (\Delta Q_1) \cup (\Delta Q_2), \\ 
\Delta(\mbox{Sum } Q)   &:=& \mbox{Sum } (\Delta Q), \\
\Delta(Q_1 \bowtie Q_2) &:=& ((\Delta Q_1) \bowtie Q_2) \cup (Q_1 \bowtie (\Delta Q_2)) \\
&& \cup\; ((\Delta Q_1) \bowtie (\Delta Q_2)).
\end{eqnarray*}

The deltas of conditions are 0 if they do not contain nested queries. The delta for a condition with a nested query
is more complicated. For example, our rule for $\Delta (x > Q)$ is
$(x > (Q \cup \Delta Q)) \bowtie (x \le Q) - (x \le (Q \cup \Delta Q)) \bowtie (x > Q)$.
We refer to \cite{koch-pods:10} for the general case of conditions.

TODO: explain minus.

Let us be precise though about computing delta queries. In general, each expression has input and output variables,
and taking a delta in general {\em adds variables} parameterizing the query with the update. From now on we only consider single-tuple insertions $+R(\vec{x})$ to or deletions $-R(\vec(x)$ from a relation $R$.
For example, given schema $R(AB), S(BC)$, the delta $+R(x,y)$ to query \\
{\tt sum(R.A * S.C) from R, S where R.B<S.B)[][]}
is \\
{\tt sum(x * S.C) from S where y < S.B[x,y][]}.
Various optimizations are possible in special cases. For example, the delta to
{\tt sum(R.A * S.C) from R, S where R.B=S.B)[][]} is \\
{\tt x * sum(S.C) from S)[][y=S.B]}. Here two things have happened. We have exploited distributivity
to pull $x$ out of the aggregation; moreover, the domain of $y$ is restricted by the database; the possible values of $y$ can be computed from the database (bottom-up), so it can be turned into an output variable.
To understand better why our delta expressions have this shape, note that \\
$\Delta_{+R(x,y)}(R[][A, B_R] \bowtie S[][B_S, C] \bowtie B_R \theta B_S)$ is \\
$(\Delta_{+R(x,y)}R[][A, B_R]) \bowtie (S[][B_S, C] \bowtie B_R \theta B_S))$ \\
+
$(\Delta_{+R(x,y)}R[][A, B_R]) \bowtie (\Delta_{+R(x,y)}(S[][B_S, C] \bowtie B_R \theta B_S)))$ \\
+
$R[][A, B_R] \bowtie (\Delta_{+R(x,y)}(S[][B_S, C] \bowtie B_R \theta B_S)))$ and \\
$\Delta_{+R(x,y)}(S[][B_S, C] \bowtie B_R \theta B_S)) = 0$ \\
since both
$\Delta_{+R(x,y)} S[][B_S, C]$ and
$\Delta_{+R(x,y)} B_R \theta B_S$ are zero.
Now
$\Delta_{+R(x,y)}(R[][A, B_R]$ is the singleton relation $\{\tuple{A:x,B_R:y}\}$: the actual insertion.
The expression $\{\tuple{A:x,B_R:y}\} \bowtie S[][B_S, C] \bowtie B_R \theta B_S)$ can be simplified to
$\{\tuple{A:x}\} \bowtie S[][B_S, C] \bowtie y \theta B_S)$.



\subsubsection{Recursive incremental view maintenance \cite{koch-pods:10}.}


Before we come to multi-level incremental view maintenance, let us recap the special case of recursive incremental view maintenance of \cite{koch-pods:10, kennedy-ahmad-koch-cidr:11}, where we try to be as greedily incremental as possible.
If we restrict our query language to exclude aggregates nested into conditions (for which the delta query was complicated), the query language fragment has the following nice property \cite{koch-pods:10}:
For any query $Q$ of the fragment, $\Delta Q$ is again a query of the fragment. Moreover,
$\Delta Q$ is structurally strictly simpler than $Q$ when query complexity is measured as follows. For union-free queries, the complexity, called {\em join-height} is the number of relations joined together. We can use distributivity to push unions above joins and so give a complexity measure to queries with unions. 

Recursive incremental view maintenance makes use of the simple fact that a delta query is a query too. Thus it can be incrementally maintained as well, making use of a delta query to the delta query, which again can be materialized and incrementally maintained, and so on, recursively.
Since delta queries are structurally simpler than the base queries, this recursive query transformation terminates, which happens when the join-height of a $k$-th delta query comes down to zero (i.e., it does not contain any database relation). This happens for $k$ equal the join-height of the input query.

The goal of compilation is to create on-insert and on-delete triggers for every relation occurring in the query.
Conceptually, a query $Q[\vec{x}_{in}][\vec{x}{out}]$ of join-height $H$ over relations $R_1, \dots, R_k$ is compiled as follows:
We write $M_Q$ for the materialized view of query $Q$. 
Then the trigger program for the event $\pm R_{i_{j+1}}(\vec{y}_{j+1})$ consists of the
statements

\noindent
foreach $\vec{x}_{out}, \vec{y}_1, \dots, \vec{y}_j$ do \\
~~~
   $M_{\Delta_{\pm R_{i_j}} \dots \Delta_{\pm R_{i_1}} Q}
       [\vec{x}_{in}\vec{y}_1 \dots \vec{y}_j][\vec{x}_{out}] \;\pm= \\
~~~~~~
    M_{\Delta_{\pm R_{i_{j+1}}} \dots \Delta_{\pm R_{i_1}} Q}
       [\vec{x}_{in}\vec{y}_1 \dots \vec{y}_{j+1}][\vec{x}_{out}]$.


\noindent
for each $j \in 1 \dots H$ and $\tuple{i_1 \dots i_j} \in {1 \dots k}^j$. Note that for correctness, unless we maintain
old and new versions of the maps (which would be costly), these statements have to be 
ordered by increasing $j$. TODO: explain.


\subsubsection{Challenges and insights.}


Explain challenges:
\begin{itemize}
\item
Delta query with input/output vars is a bulk operation: needs to be done for each var assignment to input/output vars. Output vars are essentially group by.

\item
In general, such expressions with binding patterns have to be materialized, which causes difficulties: how to determine a suitable domain for these input variables for which to materialize the results of the expressions, how to represent and store such materialized structures, and how to dynamically maintain the domains of input variables as updates add previously unseen data values.

Maintaining the right domains for the variables is a challenge, particularly for input variables. Great optimization potential and so far we only have a na‹ve solution. Assuming all the relevant variables are in the domain, it?s easy, but that is an unrealistic assumption.
\end{itemize}



We learn two lessons:
\begin{itemize}
\item
This calls for a compilers approach. Since the work gets conceptually so simple and well-behaved, we should be able to gain from doing something different from what classical query interpreters do. We have to study to what extent this is true if we return to the larger query language with nested aggs.

\item
There is a need for decomposition and factorization to make this useful. Next section.
\end{itemize}



\subsection{Initial value computation}


Theorem: case where values are zero.

Compile initial value computations for incremental evaluation. This needs non-query code.




\subsection{Join graph decomposition and factorization}
\label{sec:simplification}


In this subsection we present two query simplification techniques that are key to making
recursive incremental view maintenance useful, join graph decomposition, and factorization
of query polynomials.



\begin{verbatim}
R(AB), S(BC), T(CDE)

select sum(A*D) from natjoin(R,S,T) [][T.E]


+S(b,c):
   foreach x: q[][x] += select sum(A*D) from R,T [][E]
         = select sum(A) from R where B=b [][] *
            select sum(D) from T where C=c [][T.E/x]
\end{verbatim}


Factorization:





